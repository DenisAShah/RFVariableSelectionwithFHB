---
output:
  github_document:
    toc: TRUE
---


<!-- Data files created by this script: -->
<!--  StackedRes.RData -->


Some summaries and predictor metadata
=========

# Objective(s)
* some summaries of the base RF models that were retained by the three metalearners (lasso, ridge, elasticnet), as well as the metadata on the variables associated with the base RF models



```{r knitr-setup, include=FALSE, eval=TRUE}
options(digits = 3)
require(knitr)
## options
knitr::opts_chunk$set(eval = TRUE, echo = FALSE, cache = TRUE, fig.path = '../Figures/Ensembles/', fig.height = 5)
```

---------------------------------------------------------------------------------------


```{r Libraries, eval=TRUE, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(tidymodels)
library(stacks)
library(ranger)

library(corrr)

library(kableExtra)

tidymodels_prefer()
```


<!-- # Stacking -->
<!-- Data setup and partition -->
```{r data-setup, eval=FALSE, echo=FALSE}
## The set of variables used by the varSelRF models:
# Load the object (m1) containing the information on the models (this RData file is created by the script `varSelRF0.Rmd`):
load("../varSelRF/varSelRFResII.RData")

# Get the variables (as used across the 20 varSelRF models):
varSelRF.vars <- 
  m1 %>%
  dplyr::select(max.vars, max.no.vars, max.fmla, auc.outer) %>%
  tidyr::unnest(cols = auc.outer) %>%
  tibble::rownames_to_column() %>%
  # the 20 models:
  dplyr::filter(.estimate >= 0.92, max.no.vars >= 9, max.no.vars <= 14) %>%
  rename(vars = max.vars, no.vars = max.no.vars, fmla = max.fmla, auc = .estimate) %>%  
  dplyr::select(vars) %>%
  tidyr::unnest(cols = vars) %>%
  dplyr::distinct() %>%
  dplyr::pull(var)


## The variables used across the set of VSURF models:
# Load the saved object with the VSURF results (this RData file is created by the script `VSURF0.Rmd`):
load("../VSURF/VSURF0Res.RData")

# the id's of duplicated models:
dups <-
  vsurf %>%
  tibble::rowid_to_column() %>%
  dplyr::select(rowid, indx) %>%
  # Sort the indices:
  dplyr::mutate(sorted = map(indx, sort)) %>%
  # The filtering step identifies the duplicates:
  dplyr::group_by(sorted) %>%
  dplyr::filter(n() > 1) %>%
  # Arrange so that the duplicates are shown together:
  dplyr::arrange(sorted) %>%
  # and filter out every other:
  dplyr::filter(row_number() %% 2 == 1) %>%
  # the rowid's of the duplicates to remove:
  dplyr::pull(rowid)

# Now we filter to a subset of models to pursue further.
# Distinct, 6-9 vars, auc no less than 0.8
vsurf.filtered <-
  vsurf %>%
  tibble::rowid_to_column() %>%
  dplyr::mutate(no_vars = purrr::map(indx, length)) %>%
  dplyr::mutate(vars = map2(splits, indx, function(.splits, .indx) {
    x <- analysis(.splits) %>% select(-Y)
    names(x)[.indx]})) %>%
  dplyr::select(rowid, no_vars, auc, vars) %>%
  tidyr::unnest(cols = c(no_vars, auc)) %>%
  # just easier to call the column auc:
  dplyr::rename(auc = .estimate) %>%
  # apply our filtering criteria:
  dplyr::filter(!rowid %in% dups, no_vars %in% 6:9, auc > 0.8) 

vsurf.vars <-
  vsurf.filtered %>%
  dplyr::select(vars) %>%
  tidyr::unnest(cols = vars) %>%
  dplyr::distinct() %>%
  dplyr::pull()

# The set of vars across both sets of models (varSelRF and VSURF). There are 35 in all:
vars_sub <-
  c(varSelRF.vars, vsurf.vars) %>%
  unique()


# Load the fhb data matrix:
source("../ReadFHBDataset.R")

# Some cleanup (removal of objects not needed at this point):
rm(list = ls()[!(ls() %in% c("X", "vars_sub"))]) 

# The response and set of predictors needed to fit the different RF models:
fhb <-
  X %>%
  # Set up Y as a factor (tidymodels):
  dplyr::mutate(Y = ifelse(S < 10, "Nonepi", "Epi")) %>%
  # The first level is the one you want to predict:
  dplyr::mutate(Y = factor(Y, levels = c("Epi", "Nonepi"))) %>%
  dplyr::select(Y, all_of(vars_sub))


# Set up the data partition:
set.seed(2331)
fhb_split <- initial_split(fhb, prop = 2/3, strata = Y)
fhb_train <- training(fhb_split)
fhb_test  <- testing(fhb_split)

# Cross-validation folds:
set.seed(648)
fhb_folds <- vfold_cv(fhb_train, strata = Y, v = 5)

eval_tuned_bayes <- function(.x, .mdl) {
  # Extract the parameters for the best fit to a model, fit the training data cv folds with these tuned parameters, and obtain the predicted probabilities of an epidemic on the held out partition of the fold.
  # Args:
  #  .x = a workflowset object holding the tuning results
  #  .mdl = character string for the model, e.g. "M1"
  # Returns:
  #  a tibble with columns for the model, Y and predicted probs on the held-out cv fold
  #
  # The tuned parameters resulting in the best fit for the model:
  best_results <-
    .x %>%
    extract_workflow_set_result(.mdl) %>%
    select_best()
  
  # Extract model, fit to the training set with the tuned parameters, and evaluate on the test set:
  set.seed(1001)     # set seed for reproducibility. RF uses bootstrap sampling in building trees
  
  # For stacking we need to save the predictions and workflow:
  keep_pred <- control_resamples(save_pred = TRUE, save_workflow = TRUE)
  
  .x %>% 
    extract_workflow(.mdl) %>%           # return the workflow for model
    finalize_workflow(best_results) %>%  # update the model with the tuning parameters
    fit_resamples(resamples = fhb_folds, control = keep_pred)  # fit the updated model
  }  # end function eval_tuned_bayes
```


<!-- Set up the data stack object -->
```{r stack-setup, eval=FALSE, echo=FALSE}
# Using the Bayes tuning results for the varSelRF models:
# (Assuming the scripts in the varSelRF folder have been run and this .rds objected created)
varselrf_mods <- readRDS("../varSelRF/varSelRF1ResBayes.rds")

# Set the names of the model list:
num_mods <- 1:20
mdl <- stringr::str_c("M", num_mods)

# A list to store the varSelRF models after processing with the eval_tuned_bayes function:
varselrf_list <- vector(mode = "list", length = length(num_mods))

# Populate the list:
for (i in num_mods) {
  varselrf_list[[i]] <- eval_tuned_bayes(.x = varselrf_mods, .mdl = mdl[i])
}

# Initiate the stacking object:
fhb_st <- stacks()

# And add the varSelRF models to it:
for (i in num_mods) {
  fhb_st <- 
    fhb_st %>% 
    add_candidates(varselrf_list[[i]], name = str_c("varselrf_", mdl[i]))
}

# Don't need the large varselrf_mods object anymore:
rm(varselrf_mods)


# Now we get the tuned VSURF models:
vsurf_mods <- readRDS("../VSURF/VSURF1.rds")

# Set the names of the model list:
num_mods <- 1:38
mdl <- stringr::str_c("M", num_mods)

# A list to store the varSelRF models after processing with the eval_tuned_bayes function:
vsurf_list <- vector(mode = "list", length = length(num_mods))

# Populate the list:
for (i in num_mods) {
  vsurf_list[[i]] <- eval_tuned_bayes(.x = vsurf_mods, .mdl = mdl[i])
}

# And add the VSURF models to the stack:
for (i in num_mods) {
  fhb_st <- 
    fhb_st %>% 
    add_candidates(vsurf_list[[i]], name = str_c("vsurf_", mdl[i]))
}

# Now we are all set up for ensembling on the model stack...
rm(list = ls()[!(ls() %in% c(str_subset(ls(), "^fhb")))]) 
```


```{r stack-fit, eval=FALSE, echo=FALSE, results='hide'}
# Once you have the model stack, determine how to combine their predictions
# 1. lasso
set.seed(2331)
fhb_st.lasso <- 
  fhb_st %>%
  blend_predictions() %>%
  # fit the candidates with nonzero stacking coefficients
  fit_members()

# Out of 58 possible members, the ensemble retained six.  One from varSelRF and the others from VSURF
# varSelRF M19, vsurf M8, M10, M11, M20, M21
fhb_st.lasso
autoplot(fhb_st.lasso, type = "weights")


# 2. ridge
set.seed(2331)
fhb_st.ridge <- 
  fhb_st %>%
  blend_predictions(mixture = 0) %>%
  # fit the candidates with nonzero stacking coefficients
  fit_members()

# Out of 58 possible candidate members, the ensemble retained 11
# varselRF M19, vsurf M8, M9, M10, M11, M13, M14, M15, M20, M21, M32
fhb_st.ridge$member_fits %>% names()
autoplot(fhb_st.ridge, type = "weights")

# 3. Elastic-net
set.seed(2331)
fhb_st.en <- 
  fhb_st %>%
  blend_predictions(mixture = 0.5) %>%
  # fit the candidates with nonzero stacking coefficients
  fit_members()

# Out of 58 possible candidate members, the ensemble retained 9:
# varselRF M19, vsurf M8, M9, M10, M11, M13, M14, M20, M21
fhb_st.en$member_fits %>% names()
```


```{r stack-save-the-models, eval=FALSE, echo=FALSE}
save(fhb_st.lasso, fhb_st.ridge, fhb_st.en, file = "StackedRes.RData")
```



* We used lasso, ridge or elasticnet regression as the meta-learner.  

* Out of the 58 RF models, lasso retained 6 RF models, ridge retained 11, and elasticnet 9. Only 1 varSelRF model was retained (M19) by all three meta-learners.  The VSURF models retained varied among the meta-learners, but overall the following 10 VSURF models were retained: M8, M9, M10, M11, M13, M14, M15, M20, M21, M32. 

* That is, even though the meta-learner was fed all 58 RF models, it set the coefs for many of them to zero. The meta-learner was then trained only with the retained RF models.


----------------------------------------------------------------------------------------------


<!-- Model properties  -->
```{r load-stacked-models, eval=TRUE,echo=FALSE}
# Load the three model stacks (lasso, ridge, elasticnet)
load("StackedRes.RData")
```


# Base RF models
## lasso
### Retained models
The RF models retained by the `lasso` metalearner

```{r retained-models-lasso, eval=TRUE, echo=FALSE}
## lasso:
# The retained models:
# fhb_st.lasso$member_fits %>% names() %>% str_remove("_1_1")

# The stacking coefs for the retained models:
lasso <- 
  tibble(learner = "lasso", model = c("varselrf_M19", "vsurf_M21", "vsurf_M10", "vsurf_M11", "vsurf_M8", "vsurf_M20"), weight = c(2.92, 1.46, 1.20, 1.00, 0.319, 0.105)) 

lasso %>%
  kable(., row.names = TRUE, col.names = c("Metalearner", "Model", "Weight"))
```

### Model correlations
Pairwise correlations of the predicted probabilities of epidemics for the base RF models
```{r corr-lasso, eval=TRUE, echo=TRUE, results='markup', message=FALSE}
# The predicted probs for each of the models in the ensemble. These are the level 1 data.
lasso.probs <-
  fhb_st.lasso$data_stack %>% 
  select(contains(c("varSelRF_M19", "vsurf_M8", "vsurf_M10", "vsurf_M11", "vsurf_M20", "vsurf_M21"))) %>%
  rename_with(., ~str_remove(., ".pred_Nonepi_")) %>%
  rename_with(., ~str_remove(., "_1_1")) %>%
  # prob of Epi
  mutate(across(everything(), ~1-.))

# Using functions in the corrr package. 
# The correlation matrix:
lasso_cor <- 
  lasso.probs %>% 
  correlate(quiet = T) 

# The correlation matrix cleaned up for presentation:
lasso_cor %>%
  shave() %>%
  fashion(decimals = 3)

# How many pairwise correlations among the 6 variables:
choose(6, 2)

# The mean of the pairwise correlations:
lasso_cor %>%
  shave() %>%
  stretch(na.rm = T) %>%
  summarise(mean_r = mean(r))
  

# The highest and lowest correlations (so you have an idea of the range):
lasso_cor %>%
  shave() %>%
  stretch(na.rm = T) %>%
  arrange(r) %>%
  slice(1, n(), with_ties = FALSE)
```



## ridge
### Retained models
The RF models retained by the `ridge` metalearner

```{r retained-models-ridge, eval=TRUE, echo=FALSE}
# The retained models: there are 11
# fhb_st.ridge$member_fits %>% names() %>% str_remove("_1_1")

# but only the first 10 are printed in the tibble (vsurf_M15 is the lowest and does not appear):
# fhb_st.ridge

# so the only way I found to extract the weights is a workaround, which extracts the data used to generate the plot of the weights:
# ridgeplot <- autoplot(fhb_st.ridge, type = "weights")
# layer_data(ridgeplot, 1)  %>% select(x) %>% arrange(desc(x))

# The stacking coefs for the retained models:
ridge <-
  tibble(learner = "ridge", model = c("varselrf_M19", "vsurf_M21", "vsurf_M10", "vsurf_M11", "vsurf_M8", "vsurf_M13", "vsurf_M14", "vsurf_M9", "vsurf_M32", "vsurf_M20", "vsurf_M15"), weight = c(1.98, 1.21, 1.13, 0.892, 0.557, 0.402, 0.194, 0.156, 0.142, 0.128, 0.0548)) 

ridge %>%
  kable(., row.names = TRUE, col.names = c("Metalearner", "Model", "Weight"))
```


### Model correlations
```{r corr-ridge, eval=TRUE, echo=TRUE, results='markup', message=FALSE}
# The predicted probs for each of the models in the ensemble. These are the level 1 data.
ridge.probs <-
  fhb_st.ridge$data_stack %>% 
  select(contains(c("varselrf_M19", "vsurf_M21", "vsurf_M10", "vsurf_M11", "vsurf_M8", "vsurf_M13", "vsurf_M14", "vsurf_M9", "vsurf_M32", "vsurf_M20", "vsurf_M15"))) %>%
  rename_with(., ~str_remove(., ".pred_Nonepi_")) %>%
  rename_with(., ~str_remove(., "_1_1")) %>%
  # prob of Epi
  mutate(across(everything(), ~1-.))

# The correlation matrix:
ridge_cor <- 
  ridge.probs %>% 
  correlate(quiet = T) 

# The correlation matrix cleaned up for presentation:
ridge_cor %>%
  shave() %>%
  fashion(decimals = 3)

# How many pairwise correlations among the 6 variables:
choose(11, 2)

# The mean of the pairwise correlations:
ridge_cor %>%
  shave() %>%
  stretch(na.rm = T) %>%
  summarise(mean_r = mean(r))

# The highest and lowest correlations (so you have an idea of the range):
ridge_cor %>%
  shave() %>%
  stretch(na.rm = T) %>%
  arrange(r) %>%
  slice(1, n(), with_ties = FALSE)
```


## elasticnet
### Retained models
The RF models retained by the `elasticnet` metalearner

```{r retained-models-elasticnet, eval=TRUE, echo=FALSE}
# The retained models:
# fhb_st.en$member_fits %>% names() %>% str_remove("_1_1")

# The stacking coefs for the retained models:
en <-
  tibble(learner = "elasticnet", model = c("varselrf_M19", "vsurf_M21", "vsurf_M10", "vsurf_M11", "vsurf_M8", 'vsurf_M13', "vsurf_M20", "vsurf_M14", "vsurf_M9"), weight = c(2.25, 1.36, 1.14, 0.943, 0.541, 0.284, 0.0968, 0.0454, 0.0171)) 

en %>%
  kable(., row.names = TRUE, col.names = c("Metalearner", "Model", "Weight"))
```

### Model correlations
```{r corr-elasticnet, eval=TRUE, echo=TRUE, results='markup', message=FALSE}
# The predicted probs for each of the models in the ensemble. These are the level 1 data.
en.probs <-
  fhb_st.en$data_stack %>% 
  select(contains(c("varselrf_M19", "vsurf_M21", "vsurf_M10", "vsurf_M11", "vsurf_M8", 'vsurf_M13', "vsurf_M20", "vsurf_M14", "vsurf_M9"))) %>%
  rename_with(., ~str_remove(., ".pred_Nonepi_")) %>%
  rename_with(., ~str_remove(., "_1_1")) %>%
  # prob of Epi
  mutate(across(everything(), ~1-.))

# The correlation matrix:
en_cor <- 
  en.probs %>% 
  correlate(quiet = T) 

# The correlation matrix cleaned up for presentation:
en_cor %>%
  shave() %>%
  fashion(decimals = 3)

# How many pairwise correlations among the 6 variables:
choose(9, 2)

# The mean of the pairwise correlations:
en_cor %>%
  shave() %>%
  stretch(na.rm = T) %>%
  summarise(mean_r = mean(r))

# The highest and lowest correlations (so you have an idea of the range):
en_cor %>%
  shave() %>%
  stretch(na.rm = T) %>%
  arrange(r) %>%
  slice(1, n(), with_ties = FALSE)
```


## Weights
### Individual
List the RF models used in each of the ensembles and their weights.  We can see that `varselrf_M19`, for example, was assigned relatively high weight in each of the three ensembles. 

The table is sorted by model and then by weight.

```{r retained-models-weights, eval=TRUE, echo=FALSE}
all_ensembles <- 
  bind_rows(lasso, ridge, en)

all_ensembles %>%
  arrange(model, desc(weight)) %>%
  kable(., row.names = TRUE, col.names = c("Metalearner", "Model", "Weight"))
```


### Means
The mean weight for each model over the 3 metalearners. We also give a column (n) of the number of metalearners (out of 3) in which the base RF model was retained.  We also see that there were 11 base RF models retained across the 3 metalearners.

The table is sorted by n and then weight.

```{r retained-models-means, eval=TRUE, echo=FALSE}
all_ensembles %>%
  mutate(model = factor(model, levels = c("varselrf_M19", "vsurf_M8", "vsurf_M9", "vsurf_M10", "vsurf_M11", "vsurf_M13", "vsurf_M14", "vsurf_M15", "vsurf_M20", "vsurf_M21", "vsurf_M32"))) %>%
  add_count(model) %>%
  group_by(model) %>%
  summarise(weight = mean(weight), n = mean(n)) %>%
  arrange(desc(n), desc(weight)) %>%
  kable(., row.names = TRUE, col.names = c("Model", "Weight", "n"))
```


<!-- RF models data prep for the next two sections at least-->
```{r RF-models-data-prep, eval=TRUE, echo=FALSE}
# varSelRF models
# Load the object (m1) containing the information on the models:
load("../varSelRF/varSelRFResII.RData")

# The data on the 20 models:
varSelRF_M19 <-
  m1 %>%
  dplyr::select(max.vars, max.no.vars, max.fmla, auc.outer) %>%
  tidyr::unnest(cols = auc.outer) %>%
  tibble::rownames_to_column() %>%
  # 20 models:
  dplyr::filter(.estimate >= 0.92, max.no.vars >= 9, max.no.vars <= 14) %>%
  rename(vars = max.vars, no.vars = max.no.vars, fmla = max.fmla, auc = .estimate) %>%
  # and we want model M19:
  slice(19) %>%
  mutate(model = "varSelRF_M19", .before = vars) %>%
  mutate(vars = map(vars, function(x) x %>% pull(var))) %>%
  select(model, no.vars, vars) %>%
  # to have the same column names for varSelRF and VSURF model lists:
  rename(no_vars = no.vars)


# VSURF models:
# Load the saved object with the VSURF results:
load("../VSURF/VSURF0Res.RData")

# This gets the rowid's of duplicate models in the vsurf object:
dups <-
  vsurf %>%
  tibble::rowid_to_column() %>%
  dplyr::select(rowid, indx) %>%
  # Sort the indices:
  dplyr::mutate(sorted = map(indx, sort)) %>%
  # The filtering step identifies the duplicates:
  dplyr::group_by(sorted) %>%
  dplyr::filter(n() > 1) %>%
  # Arrange so that the duplicates are shown together:
  dplyr::arrange(sorted) %>%
  # and filter out every other:
  dplyr::filter(row_number() %% 2 == 1) %>%
  # the rowid's of the duplicates to remove:
  dplyr::pull(rowid)

# Now we filter to a subset of models to pursue further.
# Distinct, 6-9 vars, auc no less than 0.8
vsurf.filtered <-
  vsurf %>%
  tibble::rowid_to_column() %>%
  dplyr::mutate(no_vars = purrr::map(indx, length)) %>%
  dplyr::mutate(vars = map2(splits, indx, function(.splits, .indx) {
    x <- analysis(.splits) %>% select(-Y)
    names(x)[.indx]})) %>%
  dplyr::select(rowid, no_vars, auc, vars) %>%
  tidyr::unnest(cols = c(no_vars, auc)) %>%
  # just easier to call the column auc:
  dplyr::rename(auc = .estimate) %>%
  # apply our filtering criteria:
  dplyr::filter(!rowid %in% dups, no_vars %in% 6:9, auc > 0.8) %>%
  mutate(model = stringr::str_c("vsurf_M", 1:38)) %>%
  slice(c(8:11, 13:15, 20, 21, 32)) %>%
  select(model, no_vars, vars)


# The model tibble:
rf_mods <- bind_rows(varSelRF_M19, vsurf.filtered)
```

## No. variables per model
The table is sorted by the no. vars per model, and then the variables themselves are sorted by name.

```{r vars-per-model, eval=TRUE, echo=FALSE}
rf_mods %>%
  mutate(vars = map(vars, ~sort(.x))) %>%
  arrange(desc(no_vars)) %>%
  kable(., row.names = TRUE, col.names = c("RF model", "No. vars", "Variables"))
```


## No times each variable was selected {.tabset .tabset-fade .tabset-pills}
### Table
The table is sorted by count, the maximum of which is 11 (the no. of RF models)

```{r vars-freq-table, eval=TRUE, echo=FALSE}
rf_mods %>%
  select(vars) %>%
  unnest(cols = vars) %>%
  count(vars) %>%
  arrange(desc(n), vars) %>%
  kable(., row.names = TRUE, col.names = c("Variables", "Count"))
```

### Graph
```{r vars-freq-graph, eval=TRUE, echo=FALSE}
rf_mods %>%
  select(vars) %>%
  unnest(cols = vars) %>%
  count(vars) %>%
  arrange(n, vars) %>%
  # Easier to visualize...
  # This trick updates the factor levels:
  dplyr::mutate(vars = factor(vars, levels = vars)) %>%   
  ggplot(aes(x = vars, y = n)) +
  geom_segment(aes(xend = vars, yend = 0)) +
  geom_point(size = 4, colour = "grey60") +
  scale_y_continuous(breaks = seq(0, 12, 2)) +
  coord_flip() +
  theme_bw() +
  xlab("") +
  ylab("Frequency")
```



# Metadata
<!-- Variables meta-data -->
```{r Metadata-prep, eval=TRUE, echo=FALSE}
# The variables metadata:
io <- readr::read_csv("../Data/VariableMetaData.csv", show_col_types = FALSE)


# vars_sub is a character vector of the 22 distinct weather variables (resist is excluded) used among the RF models
vars_sub <-
  rf_mods %>%
  select(vars) %>%
  unnest(cols = vars) %>%
  dplyr::distinct() %>%
  dplyr::filter(!vars == "resist") %>%
  dplyr::pull(vars)

# The meta-data associated with these 22 weather variables: 
io.s <-
   io %>% 
   dplyr::filter(variable_name %in% vars_sub)
```


```{r Helper-functions, eval=TRUE, echo=FALSE}
# Helper functions (to avoid decimal breaks in the axis tick labels):
# https://stackoverflow.com/questions/61915427/ggplot-integer-breaks-on-facets
my_ceil <- function(x) {
  ceil <- ceiling(max(x))
  ifelse(ceil > 1 & ceil %% 2 == 1, ceil + 1, ceil)
}

my_breaks <- function(x) { 
  ceil <- my_ceil(max(x))
  unique(ceiling(pretty(seq(0, ceil))))
} 

my_limits <- function(x) { 
  ceil <- my_ceil(x[2])
  c(x[1], ceil)
}
```


## Descriptive summary
This set has 22 variables. 

```{r metadata-descriptive-summary, eval=TRUE, echo=FALSE}
io.s %>%
  dplyr::select(source, variable_name, summary, win_start_period, win_start_day, win_end_period, win_end_day, win_length) %>%
  kable(., row.names = TRUE, col.names = c("Source", "Name", "Summary", "Window start period", "Window start day", "Window end period", "Window end day", "Window length"))
```


## Variable type
* all 7 types are represented

### All types
```{r metadata-variable-type-all, eval=TRUE, echo=FALSE}
io.s %>%
  dplyr::count(type) %>%
  kable(., row.names = TRUE, col.names = c("Type", "Count"))
```


### By meta-group
Moisture-indicating variables (RH, TDD, VPD) all in one group

```{r  metadata-variable-type-group, eval=TRUE, echo=FALSE}
io.s %>%
  mutate(metagroup = ifelse(type %in% c("RH", "TDD", "VPD"), "Moisture-related", "Other")) %>%
  dplyr::count(metagroup) %>%
  kable(., row.names = TRUE, col.names = c("Meta-group", "Count"))
```



## Metric
* i.e., does the variable summarize a count (e.g., no. of hr) or mean?
* about two-thirds of the variables are means

```{r metadata-metric, eval=TRUE, echo=FALSE}
io.s %>%
  dplyr::count(metric) %>%
  kable(., row.names = TRUE, col.names = c("Metric", "Count"))
```


## Window start day
* several different window start days pre-anthesis
* all post-anthesis variables start at anthesis

### Graph
```{r metadata-window-start-day-graph, eval=TRUE, echo=FALSE}
# the start day of the window which the variable summarizes
io.s %>%
  dplyr::count(period, win_start_day) %>%
  # Easier to visualize:
  ggplot(., aes(x = n, y = win_start_day)) +
  geom_segment(aes(yend = win_start_day), xend = 0, colour = "grey50") +
  geom_point(size = 3, colour = "cornflowerblue") +
  facet_wrap(~period, ncol = 3) +
  # makes use of the helper functions:
  scale_x_continuous(breaks = my_breaks, limits = my_limits) +
  theme_bw() +
  xlab("No. of variables") +
  ylab("Window start day") +
  # No horizontal grid lines:
  theme(panel.grid.major.y = element_blank())
```


### Summary (pre-anthesis variables)
All post-anthesis variables began at anthesis
```{r metadata-window-start-day-summary-pre, eval=TRUE, echo=FALSE}
# The average start day for pre-anthesis variables:
io.s %>%
  dplyr::filter(period == "pre") %>%
  dplyr::summarise(min_start_day = min(win_start_day), ave_start_day = mean(win_start_day), max_start_day = max(win_start_day)) %>%
   kable(., row.names = TRUE, col.names = c("Window start (min)", "Window start (mean)", "Window start (max)"))
```


## Window end day 
Besides four variables, all other pre-anthesis variable windows end at anthesis, of course.

The Table below is for the post-anthesis variables, all of which start at anthesis.
```{r metadata-window-end-day-summary-post, eval=TRUE, echo=FALSE}
io.s %>%
  dplyr::filter(period == "post") %>%
  dplyr::summarise(min_end_day = min(win_end_day), ave_end_day = mean(win_end_day), max_end_day = max(win_end_day)) %>%
   kable(., row.names = TRUE, col.names = c("Window end (min)", "Window end (mean)", "Window end (max)"))
```




## Window length
* the length (days) of the window the variable summarizes
* they are various

### Graph
```{r metadata-window-length-graph, eval=TRUE, echo=FALSE}
io.s %>%
  dplyr::count(period, win_length) %>%
  # Easier to visualize:
  ggplot(., aes(x = n, y = win_length)) +
  geom_segment(aes(yend = win_length), xend = 0, colour = "grey50") +
  geom_point(size = 3, colour = "cornflowerblue") +
  facet_wrap(~period, ncol = 3) +
  theme_bw() +
  xlab("No. of variables") +
  ylab("Window length") +
  # No horizontal grid lines:
  theme(panel.grid.major.y = element_blank())
```


### Table
Average window length for each group
```{r metadata-window-length-table, eval=TRUE, echo=FALSE}
io.s %>%
  dplyr::select(period, win_length) %>%
  dplyr::group_by(period) %>%
  dplyr::summarise(n = n(), min_win_length = min(win_length), mean_win_length = mean(win_length), max_win_length = max(win_length)) %>%
  kable(., row.names = TRUE, col.names = c("Period", "Count", "Min window length", "Mean window length", "Max window length"))
```



## Number of variables by period
* 55% are pre-anthesis variables

```{r metadata-num-vars-by-period, eval=TRUE, echo=FALSE}
io.s %>%
  dplyr::count(period) %>%
  kable(., row.names = TRUE, col.names = c("Period", "Count"))
```

### All pre-anthesis variables
```{r metadata-pre-vars, eval=TRUE, echo=FALSE}
io.s %>%
   dplyr::filter(period == "pre") %>%
   dplyr::arrange(type) %>%
   dplyr::select(variable_name, summary, win_start_period, win_end_period, win_start_day, 
                 win_end_day, win_length) %>%
   # row.names just to get numbering:
   kable(., row.names = TRUE, col.names = c("Variable", "Summary", "Window start period", "Window end period", "Window start day", "Window end day", "Window length"))
```

### All post-anthesis variables
```{r metadata-post-vars, eval=TRUE, echo=FALSE}
io.s %>%
   dplyr::filter(period == "post") %>%
   dplyr::arrange(type) %>%
   dplyr::select(variable_name, summary, win_start_period, win_end_period, win_start_day, 
                 win_end_day, win_length) %>%
   kable(., row.names = TRUE, col.names = c("Variable", "Summary", "Window start period", "Window end period", "Window start day", "Window end day", "Window length"))
```

### All pre-post variables
```{r metadata-prepost-vars, eval=TRUE, echo=FALSE}
io.s %>%
  dplyr::filter(period == "pre-post") %>%
  dplyr::arrange(type) %>%
  dplyr::select(variable_name, summary, win_start_period, win_end_period, win_start_day, 
                 win_end_day, win_length) %>%
  kable(., row.names = TRUE, col.names = c("Variable", "Summary", "Window start period", "Window end period", "Window start day", "Window end day", "Window length"))
```


## By type of summary and the time step interval
* That is, type of summary (count or mean), and the time step interval for the summary (hourly or daily)
* the majority are daily means

```{r metadata-metric-time-step, eval=TRUE, echo=FALSE}
io.s %>%
  dplyr::count(metric, time_step) %>%
  kable(., row.names = TRUE, col.names = c("Metric", "Time step", "Count"))
```


### the count daily <cond> variables
```{r metadata-count-daily, eval=TRUE, echo=FALSE}
io.s %>%
  dplyr::filter(metric == "count", time_step == "daily") %>%
  dplyr::select(variable_name, summary, starts_with("win_")) %>%
  kable(., row.names = TRUE, col.names = c("Variable", "Summary", "Window start day", "Window start period", "Window end day", "Window end period", "Window length"))
```

### the count hourly <cond> variables
```{r metadata-count-hourly, eval=TRUE, echo=FALSE}
io.s %>%
  dplyr::filter(metric == "count", time_step == "hourly") %>%
  dplyr::select(variable_name, summary, starts_with("win_")) %>%
  kable(., row.names = TRUE, col.names = c("Variable", "Summary", "Window start day", "Window start period", "Window end day", "Window end period", "Window length"))
```

### the mean daily <cond> variables
```{r metadata-mean-daily, eval=TRUE, echo=FALSE}
io.s %>%
  dplyr::filter(metric == "mean", time_step == "daily") %>%
  dplyr::select(variable_name, summary, starts_with("win_")) %>%
  kable(., row.names = TRUE, col.names = c("Variable", "Summary", "Window start day", "Window start period", "Window end day", "Window end period", "Window length"))
```


## Start and end periods 
* Most variables (16 out of 22) are anchored at anthesis and then extend either into the pre- or post-anthesis period
* Two variables span the pre- to post- period
* Four are confined to windows in the pre- period (not extending to anthesis)

```{r metadata-start-end-periods, eval=TRUE, echo=FALSE}
io.s %>%
  dplyr::count(win_start_period, win_end_period) %>%
  kable(., row.names = TRUE, col.names = c("Window start period", "Window end period", "Count"))
```



# Computational environment
```{r SessionInfo, eval=TRUE, echo=FALSE, results='markup'}
R.Version()$version.string
R.Version()$system
sessionInfo()
```